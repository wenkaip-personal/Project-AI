{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To model the probability distribution over the discrete number of components $K$ given the observed data $x$, we can use a categorical distribution. The categorical distribution is a generalization of the Bernoulli distribution for a discrete random variable with more than two possible outcomes.\n",
    "\n",
    "In our case, $K$ represents the number of components in the burst model, which is a discrete value. The categorical distribution allows us to assign probabilities to each possible value of $K$.\n",
    "\n",
    "One common approach is to use a neural network to learn the parameters of the categorical distribution. The network takes the observed data $x$ as input and outputs a vector of probabilities $\\mathbf{p} = (p_1, p_2, \\ldots, p_N)$, where $p_i$ represents the probability of $K$ being equal to $i$, and $N$ is the maximum number of components we consider.\n",
    "\n",
    "Here's an example of how we can define the neural network for modeling $p_{\\text{num}}(K \\mid x)$:\n",
    "\n",
    "```python\n",
    "class CategoricalModel(nn.Module):\n",
    "    def __init__(self, x_dim, max_components):\n",
    "        super(CategoricalModel, self).__init__()\n",
    "        self.max_components = max_components\n",
    "        self.fc1 = nn.Linear(x_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, max_components)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        probs = self.softmax(x)\n",
    "        return probs\n",
    "```\n",
    "\n",
    "In this example, the `CategoricalModel` is a neural network that takes the observed data `x` as input and outputs a vector of probabilities over the possible values of $K$. The network consists of three fully connected layers with ReLU activation, followed by a softmax layer to ensure the output probabilities sum up to 1.\n",
    "\n",
    "To train the model, we can use the negative log-likelihood loss, which is equivalent to the cross-entropy loss for categorical distributions:\n",
    "\n",
    "```python\n",
    "def categorical_loss(probs, targets):\n",
    "    return -torch.log(probs[torch.arange(probs.shape[0]), targets]).mean()\n",
    "```\n",
    "\n",
    "Here, `probs` is the output of the `CategoricalModel`, and `targets` is the ground truth values of $K$ for each training example.\n",
    "\n",
    "Regarding the issues with the Poisson distribution, it has some limitations when modeling the number of components:\n",
    "\n",
    "1. The Poisson distribution assumes that the mean and variance of the distribution are equal, which may not hold true for the number of components in our burst model.\n",
    "\n",
    "2. The Poisson distribution is unbounded, meaning it assigns non-zero probability to an infinite number of possible values. In practice, we may have an upper limit on the number of components we consider.\n",
    "\n",
    "3. The Poisson distribution has a single parameter (the rate parameter) that determines both the mean and variance. This may not provide enough flexibility to capture the true distribution of the number of components.\n",
    "\n",
    "In contrast, the categorical distribution allows us to learn a separate probability for each possible value of $K$, providing more flexibility in modeling the distribution.\n",
    "\n",
    "By combining the `CategoricalModel` for $p_{\\text{num}}(K \\mid x)$ with our existing `DeepSetFMPE` model for $p_{\\text{peaks}}(\\{t_0^{(k)}, A^{(k)}, s^{(k)}, r^{(k)}\\}_{k=1}^{K} \\mid x, K)$, we can model the complete posterior distribution $p_{\\text{num}}(K \\mid x) p_{\\text{peaks}}(\\{t_0^{(k)}, A^{(k)}, s^{(k)}, r^{(k)}\\}_{k=1}^{K} \\mid x, K)$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
